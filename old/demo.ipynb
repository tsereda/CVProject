{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation with ConvNeXt + FPN\n",
    "\n",
    "This notebook demonstrates how to create a semantic segmentation model using:\n",
    "- ConvNeXt backbone from timm (could be swapped with PVT or Swin)\n",
    "- Feature Pyramid Network (FPN) decoder\n",
    "- PyTorch training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the FPN Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class FPNDecoder(nn.Module):\n",
    "    def __init__(self, in_channels: List[int], out_channels: int = 256):\n",
    "        super().__init__()\n",
    "        self.lateral_convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_ch, out_channels, 1)\n",
    "            for in_ch in in_channels\n",
    "        ])\n",
    "        self.fpn_convs = nn.ModuleList([\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "            for _ in range(len(in_channels))\n",
    "        ])\n",
    "        \n",
    "    def forward(self, features: List[torch.Tensor]) -> List[torch.Tensor]:\n",
    "        # Convert input features to same channel dimension\n",
    "        laterals = [conv(feature) for feature, conv in zip(features, self.lateral_convs)]\n",
    "        \n",
    "        # Top-down pathway\n",
    "        fpn_features = [laterals[-1]]\n",
    "        for lateral in reversed(laterals[:-1]):\n",
    "            # Upsample previous feature\n",
    "            prev_feature = F.interpolate(\n",
    "                fpn_features[-1],\n",
    "                size=lateral.shape[-2:],\n",
    "                mode='nearest'\n",
    "            )\n",
    "            # Add lateral connection\n",
    "            fpn_feature = lateral + prev_feature\n",
    "            fpn_features.append(fpn_feature)\n",
    "            \n",
    "        # Apply 3x3 convs and reverse list to maintain original order\n",
    "        fpn_features = fpn_features[::-1]\n",
    "        output_features = [\n",
    "            conv(feature) for feature, conv in zip(fpn_features, self.fpn_convs)\n",
    "        ]\n",
    "        \n",
    "        return output_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the Complete Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class SegmentationModel(nn.Module):\n",
    "    def __init__(self, num_classes: int, backbone_name: str = 'convnext_tiny'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load backbone and remove classification head\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name,\n",
    "            pretrained=True,\n",
    "            features_only=True,\n",
    "            out_indices=(1, 2, 3, 4)\n",
    "        )\n",
    "        \n",
    "        # Get feature dimensions from backbone\n",
    "        dummy_input = torch.randn(1, 3, 224, 224)\n",
    "        features = self.backbone(dummy_input)\n",
    "        in_channels = [feat.shape[1] for feat in features]\n",
    "        \n",
    "        # Initialize FPN\n",
    "        self.fpn = FPNDecoder(in_channels)\n",
    "        \n",
    "        # Final prediction layers\n",
    "        self.seg_convs = nn.ModuleList([\n",
    "            nn.Conv2d(256, num_classes, 3, padding=1)\n",
    "            for _ in range(len(in_channels))\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        # Get backbone features\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Apply FPN\n",
    "        fpn_features = self.fpn(features)\n",
    "        \n",
    "        # Generate predictions at each scale\n",
    "        predictions = {}\n",
    "        for i, (feature, conv) in enumerate(zip(fpn_features, self.seg_convs)):\n",
    "            pred = conv(feature)\n",
    "            # Upsample to input resolution\n",
    "            pred = F.interpolate(\n",
    "                pred,\n",
    "                size=x.shape[-2:],\n",
    "                mode='bilinear',\n",
    "                align_corners=False\n",
    "            )\n",
    "            predictions[f'p{i}'] = pred\n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_step(model: nn.Module,\n",
    "               images: torch.Tensor,\n",
    "               masks: torch.Tensor,\n",
    "               criterion: nn.Module,\n",
    "               optimizer: torch.optim.Optimizer) -> float:\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    predictions = model(images)\n",
    "    \n",
    "    # Calculate loss (using predictions from finest scale)\n",
    "    loss = criterion(predictions['p0'], masks)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def validate(model: nn.Module,\n",
    "            val_loader: torch.utils.data.DataLoader,\n",
    "            criterion: nn.Module) -> float:\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            predictions = model(images)\n",
    "            loss = criterion(predictions['p0'], masks)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    return val_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize model\n",
    "model = SegmentationModel(\n",
    "    num_classes=21,  # For example, Pascal VOC classes\n",
    "    backbone_name='convnext_tiny'  # Can be changed to 'pvt_v2_b0' or 'swin_tiny_patch4_window7_224'\n",
    ")\n",
    "\n",
    "# Setup training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Example training loop (assuming you have your dataloaders set up)\n",
    "'''\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for images, masks in train_loader:\n",
    "        loss = train_step(model, images, masks, criterion, optimizer)\n",
    "        epoch_loss += loss\n",
    "        \n",
    "    # Validation\n",
    "    val_loss = validate(model, val_loader, criterion)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f'Training Loss: {epoch_loss/len(train_loader):.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_prediction(image: torch.Tensor,\n",
    "                        mask: torch.Tensor,\n",
    "                        prediction: torch.Tensor):\n",
    "    \n",
    "    # Convert tensors to numpy\n",
    "    image = image.cpu().permute(1, 2, 0).numpy()\n",
    "    mask = mask.cpu().numpy()\n",
    "    prediction = prediction.argmax(dim=0).cpu().numpy()\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Input Image')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(mask)\n",
    "    ax2.set_title('Ground Truth')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3.imshow(prediction)\n",
    "    ax3.set_title('Prediction')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}